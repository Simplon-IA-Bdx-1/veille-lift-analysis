{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " - La lift est une **métrique de performance** comme le Log-Loss, l'Accuracy, l'AUC, etc.\n",
    " - La lift est utilisée pour des problématiques de **classfication**\n",
    " - La lift c'est le **ratio** entre les exemples positifs correctement prédits et les exemples positifs réels dans l'ensemble de données du test\n",
    " - La lift est souvent utilisée en marketing\n",
    " - La lift s'utilise lorsque les **classes ne sont pas réparties uniformément**:\n",
    "     - Exemple : Détection de fraude\n",
    "     - Exemple : Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Dans l'exemple de la fraude, si l'on considère que 2% des transactions sont frauduleuses alors un modèle peut prédire que personne ne fraude, il aura tout de même une accuracy de 98% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple du churn\n",
    "\n",
    " - On souhaite prédire si l'utilisateur va résilier son abonnement Netflix :\n",
    "     - 1 = Classe positive\n",
    "     - 0 = Classe négative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Étapes pour déterminer la lift :\n",
    "    - On classe le jeu de données selon la probabilité de churn (0 à 1)\n",
    "    - On divisent le jeu de données en intervalles contenant le même nombre de données (décile : 0-0,1, 0,1-0,2, 0,2-0,3, etc.)\n",
    "    - On détermine pour chaque groupe le poucentage de churn (nombre de churn / effectif total du groupe)\n",
    "    \n",
    "<img src=\"lift-chart-churn-rate.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{equation*}\n",
    "\\text{lift} = \\frac{TP/(TP+FP)}{(TP+FN)/(TP+TN+FP+FN)}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\\begin{equation*}\n",
    "\\text{lift (0.9-1.0)} = \\frac{Taux prédit}{Taux moyen} = \\frac{0.97}{0.2} = 4,85\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\text{lift (0.8-0.9)} = \\frac{Taux prédit}{Taux moyen} = \\frac{0.36}{0.2} = 1.80\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc 4,85 fois plus de chance de retenir un utilisateur sur le départ que si on avait fait un choix aléatoire. On optimise donc le ciblage marketing des utilisateurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "1000 lignes, 10 groupes de 100. On trace en noire le churn moyen (ici 200/1000 soit 20%)\n",
    "\n",
    "Dans le dernier groupe (0,9 - 1,0) contenant les 100 consommateurs ayant la plus forte probabilité de churn, on constate que 97% d'entre eux ont réellement churn.\n",
    "\n",
    "\n",
    "Additionally, I drew a black line for the hypothetical average churn rate (20%). This is useful to define a targeting threshold: scores below the threshold will be set to 0, scores above to 1.\n",
    "\n",
    "This is a binary classification problem: the user either cancels the subscription (churn=1) or keeps it (churn=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Code Python\n",
    "### Librairie mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1111111111111112"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import lift_score\n",
    "\n",
    "y_target =    np.array([0, 0, 1, 0, 0, 1, 1, 1, 1, 1])\n",
    "y_predicted = np.array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
    "\n",
    "lift_score(y_target, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using lift_score in GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# make custom scorer\n",
    "lift_scorer = make_scorer(lift_score)\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=123)\n",
    "\n",
    "hyperparameters = [{'kernel': ['rbf'],\n",
    "                    'gamma': [1e-3, 1e-4],\n",
    "                    'C': [1, 10, 100, 1000]}\n",
    "                  ]\n",
    "\n",
    "clf = GridSearchCV(SVC(), hyperparameters, cv=10,  scoring=lift_scorer)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ressources :\n",
    " - [Lift Analysis – A Data Scientist’s Secret Weapon](https://www.kdnuggets.com/2016/03/lift-analysis-data-scientist-secret-weapon.html)\n",
    " - [Lift Score](https://rasbt.github.io/mlxtend/user_guide/evaluate/lift_score/)\n",
    " - [The ultimate guide to binary classification metrics](https://towardsdatascience.com/the-ultimate-guide-to-binary-classification-metrics-c25c3627dd0a#248c)\n",
    " - [Understand Gain and Lift Charts](https://www.listendata.com/2014/08/excel-template-gain-and-lift-charts.html)\n",
    " - [11 Important Model Evaluation Metrics for Machine Learning Everyone should know](https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/)\n",
    " - [MLxtend](https://rasbt.github.io/mlxtend/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
